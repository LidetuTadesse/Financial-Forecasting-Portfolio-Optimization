{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9d8b18",
   "metadata": {},
   "source": [
    "## Imports & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd56ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import plotting\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
    "\n",
    "# Paths\n",
    "PROCESSED_PRICES = Path(\"data/processed/prices_adj.csv\")\n",
    "TASK2_TSLA_FORECAST = Path(\"outputs/task2_tsla_forecast.csv\")   # expected: columns ['Date','Forecast']\n",
    "FIG_PATH = Path(\"reports/figures/task4_efficient_frontier.png\")\n",
    "WEIGHTS_PATH = Path(\"outputs/task4_optimal_weights.csv\")\n",
    "PERF_PATH = Path(\"outputs/task4_portfolio_performance.txt\")\n",
    "EXPECTED_RETURNS_PATH = Path(\"outputs/task4_expected_returns.csv\")\n",
    "\n",
    "# Create output dirs\n",
    "FIG_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "WEIGHTS_PATH.parent.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a741d41e",
   "metadata": {},
   "source": [
    "## Load prices & compute daily returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f4d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prices and verify tickers\n",
    "prices = pd.read_csv(PROCESSED_PRICES, parse_dates=[\"Date\"], index_col=\"Date\").sort_index()\n",
    "tickers = [\"TSLA\", \"BND\", \"SPY\"]\n",
    "assert all(t in prices.columns for t in tickers), \"Missing required tickers in prices_adj.csv\"\n",
    "\n",
    "# Daily returns\n",
    "returns = prices[tickers].pct_change().dropna()\n",
    "\n",
    "# Annualize covariance via Ledoit-Wolf shrinkage (more stable)\n",
    "S = CovarianceShrinkage(prices[tickers]).ledoit_wolf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ba104",
   "metadata": {},
   "source": [
    "## Build expected returns vector (TSLA from forecast, BND/SPY from history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1033d91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annualize_from_daily(daily_returns: pd.Series) -> float:\n",
    "    mu_daily = daily_returns.mean()\n",
    "    return (1 + mu_daily) ** 252 - 1\n",
    "\n",
    "# Historical expected annual returns for BND & SPY\n",
    "exp_bnd = annualize_from_daily(returns[\"BND\"])\n",
    "exp_spy = annualize_from_daily(returns[\"SPY\"])\n",
    "\n",
    "# TSLA expected annual return from forecast (preferred) or fallback\n",
    "use_fallback = False\n",
    "if TASK2_TSLA_FORECAST.exists():\n",
    "    fc = pd.read_csv(TASK2_TSLA_FORECAST, parse_dates=[\"Date\"])\n",
    "    fc = fc.sort_values(\"Date\").set_index(\"Date\")\n",
    "    if \"Forecast\" not in fc.columns:\n",
    "        raise ValueError(\"Task 2 forecast file must contain a 'Forecast' column.\")\n",
    "    # Forecasted daily returns from forecasted price path\n",
    "    tsla_fc_daily = fc[\"Forecast\"].pct_change().dropna()\n",
    "    if tsla_fc_daily.empty:\n",
    "        use_fallback = True\n",
    "    else:\n",
    "        exp_tsla = annualize_from_daily(tsla_fc_daily)\n",
    "else:\n",
    "    use_fallback = True\n",
    "\n",
    "if use_fallback:\n",
    "    # Fallback: last 252 trading days of TSLA historical data\n",
    "    tsla_last_year = returns[\"TSLA\"].dropna().iloc[-252:]\n",
    "    exp_tsla = annualize_from_daily(tsla_last_year)\n",
    "    print(\"TSLA forecast file not found or invalid; using last-year historical mean as fallback.\")\n",
    "\n",
    "# Expected returns vector\n",
    "mu = pd.Series({\"TSLA\": exp_tsla, \"BND\": exp_bnd, \"SPY\": exp_spy})\n",
    "mu.to_csv(EXPECTED_RETURNS_PATH)\n",
    "print(\"Expected annual returns (from forecast + history):\")\n",
    "display(mu.to_frame(\"ExpectedAnnualReturn\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5847635d",
   "metadata": {},
   "source": [
    "## Efficient Frontier with custom expected returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f84cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "ef = EfficientFrontier(mu, S)\n",
    "\n",
    "# To plot a smooth frontier, we reconstruct it with many target returns\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "plotting.plot_efficient_frontier(ef, ax=ax, show_assets=True)\n",
    "plt.title(\"Forecast-Driven Efficient Frontier (TSLA from forecast; BND/SPY from history)\")\n",
    "plt.xlabel(\"Volatility (Risk)\")\n",
    "plt.ylabel(\"Expected Return\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(FIG_PATH, dpi=150)\n",
    "print(f\"Saved frontier plot to {FIG_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b3bccb",
   "metadata": {},
   "source": [
    "## Identify & mark key portfolios: Max Sharpe and Min Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbee8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute key portfolios\n",
    "ef_max = EfficientFrontier(mu, S)\n",
    "w_max_sharpe = ef_max.max_sharpe()\n",
    "w_max_sharpe = ef_max.clean_weights()\n",
    "perf_max = ef_max.portfolio_performance()  # (ret, vol, sharpe)\n",
    "\n",
    "ef_min = EfficientFrontier(mu, S)\n",
    "w_min_vol = ef_min.min_volatility()\n",
    "w_min_vol = ef_min.clean_weights()\n",
    "perf_min = ef_min.portfolio_performance()\n",
    "\n",
    "# Plot with markers\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "plotting.plot_efficient_frontier(ef, ax=ax, show_assets=True)\n",
    "\n",
    "# Scatter the two portfolios\n",
    "ret_max, vol_max, sharpe_max = perf_max\n",
    "ret_min, vol_min, sharpe_min = perf_min\n",
    "\n",
    "ax.scatter([vol_max], [ret_max], marker=\"*\", s=250, label=\"Max Sharpe\", zorder=5)\n",
    "ax.scatter([vol_min], [ret_min], marker=\"o\", s=200, label=\"Min Vol\", zorder=5)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(\"Efficient Frontier with Key Portfolios\")\n",
    "ax.set_xlabel(\"Volatility (Risk)\")\n",
    "ax.set_ylabel(\"Expected Return\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save plot\n",
    "fig.savefig(FIG_PATH, dpi=150)\n",
    "print(f\"Updated frontier plot (with markers) saved to {FIG_PATH}\")\n",
    "\n",
    "# Save weights & performance\n",
    "summary = {\n",
    "    \"MaxSharpe\": {\"weights\": w_max_sharpe, \"performance\": {\"return\": ret_max, \"vol\": vol_max, \"sharpe\": sharpe_max}},\n",
    "    \"MinVol\":    {\"weights\": w_min_vol,    \"performance\": {\"return\": ret_min, \"vol\": vol_min, \"sharpe\": sharpe_min}},\n",
    "}\n",
    "pd.Series(w_max_sharpe, name=\"MaxSharpe\").to_csv(WEIGHTS_PATH)\n",
    "with open(PERF_PATH, \"w\") as f:\n",
    "    f.write(\"Max Sharpe Portfolio:\\n\")\n",
    "    f.write(f\"Expected Return: {ret_max:.4f}\\nVolatility: {vol_max:.4f}\\nSharpe Ratio: {sharpe_max:.4f}\\n\\n\")\n",
    "    f.write(\"Min Volatility Portfolio:\\n\")\n",
    "    f.write(f\"Expected Return: {ret_min:.4f}\\nVolatility: {vol_min:.4f}\\nSharpe Ratio: {sharpe_min:.4f}\\n\")\n",
    "\n",
    "print(\"Saved weights and performance to outputs/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d90ee4",
   "metadata": {},
   "source": [
    "## Choose and print a recommended portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68750502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose recommendation policy:\n",
    "RECOMMEND = \"MaxSharpe\"   # or \"MinVol\"\n",
    "\n",
    "if RECOMMEND == \"MaxSharpe\":\n",
    "    chosen_w = w_max_sharpe\n",
    "    chosen_perf = perf_max\n",
    "    rationale = \"Prioritizing maximum risk-adjusted return (Sharpe).\"\n",
    "else:\n",
    "    chosen_w = w_min_vol\n",
    "    chosen_perf = perf_min\n",
    "    rationale = \"Prioritizing lower absolute risk (minimum volatility).\"\n",
    "\n",
    "ret_c, vol_c, sharpe_c = chosen_perf\n",
    "\n",
    "print(\"=== Recommended Portfolio ===\")\n",
    "print(f\"Policy: {RECOMMEND} â€” {rationale}\")\n",
    "print(\"Weights:\")\n",
    "for k, v in chosen_w.items():\n",
    "    print(f\"  {k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nPerformance (annualized):\")\n",
    "print(f\"  Expected Return: {ret_c:.4f}\")\n",
    "print(f\"  Volatility:      {vol_c:.4f}\")\n",
    "print(f\"  Sharpe Ratio:    {sharpe_c:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
